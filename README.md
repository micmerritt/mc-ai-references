# AI Security Reference Library

## 0. Mic Merritt -- Selected Publications
Read my presentations, papers, and articles on AI Security related topics:

## 1. Overview and Scope
A public repository for research papers, books, and other documents focused on AI Security, Machine Learning, Policy, Compliance, Ethics, and more.

## 2. Threat Models in AI Systems
* Adversarial inputs
* Data poisoning
* Model extraction and cloning
* Supply-chain and dependency attacks

## 3. Attack Techniques
### 3.1 Adversarial Example Generation  
### 3.2 Prompt and Jailbreak Attacks (LLMs)  
### 3.3 Data and Label Poisoning  
### 3.4 Model Inversion and Membership Inference  
### 3.5 Side-Channel and Timing Attacks  

## 4. Defensive Strategies
### 4.1 Robust Training and Regularization  
### 4.2 Detection and Filtering  
### 4.3 Certified Robustness and Formal Verification  
### 4.4 Differential Privacy and Privacy-Preserving ML  
### 4.5 Watermarking and Provenance Tracking  

## 5. Secure Deployment and MLOps
* Model signing and integrity checks  
* Secrets, keys, and credential management  
* Runtime monitoring and logging  
* Incident response playbooks for ML pipelines  

## 6. Governance, Risk, and Compliance
### 6.1 NIST AI Risk Management Framework (AI RMF)  
### 6.2 ISO/IEC 42001 and Related Standards  
### 6.3 Policy, Ethics, and Responsible AI  
### 6.4 Sector-Specific Regulations (health, finance, defense)  

## 7. AI Red Teaming and Security Testing
* Automated red-teaming frameworks  
* Manual prompt engineering workflows  
* Benchmarks and scoring metrics  

## 8. Datasets, Benchmarks, and Evaluation Suites
* Robustness and adversarial datasets  
* Safety and bias benchmarks  
* LLM jailbreak scorecards  

## 9. Tools and Frameworks
> Pinned list of open-source projects (e.g., RobustBench, Counterfit, OpenAI evals, Guardrails, Metaguard, Tracetune).

## 10. Case Studies and Incident Reports
* Real-world failures and post-mortems  
* Industry whitepapers and government analyses  

## 11. Emerging Topics
* Retrieval-augmented generation security  
* Multi-modal model threats  
* AI agents and autonomous decision loops  
* Hardware accelerators and side channels  